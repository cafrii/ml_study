{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2ec9261",
   "metadata": {},
   "source": [
    "https://docs.pytorch.org/docs/stable/nn.html\n",
    "\n",
    "docs/torch.nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4037b953",
   "metadata": {},
   "source": [
    "## Containers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45367aa3",
   "metadata": {},
   "source": [
    "## Convolution Layers\n",
    "\n",
    "### nn.Conv2d\n",
    "여러 개의 입력 평면으로 구성된 입력 신호에 2D 합성곱을 적용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c36a73",
   "metadata": {},
   "source": [
    "```\n",
    "class torch.nn.Conv2d(in_channels, out_channels, kernel_size,\n",
    "                      stride=1, padding=0, dilation=1, groups=1,\n",
    "                      bias=True, padding_mode='zeros', device=None, dtype=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc67ae5a",
   "metadata": {},
   "source": [
    "https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d\n",
    "\n",
    "여러 입력 평면으로 구성된 입력 신호에 2D 컨볼루션을 적용합니다.\n",
    "\n",
    "가장 간단한 경우, 입력 크기 $(N, C_{\\text{in}}, H, W)$, 그리고 출력 $(N, C_{\\text{out}}, H_{\\text{out}}, W_{\\text{out}})$ 에 따른 레이어의 출력 값은 정확하게 다음과 같이 기술될 수 있습니다.\n",
    "\n",
    "$$ \\text{out}(N_i, C_{\\text{out}_j}) = \\text{bias}(C_{\\text{out}_j}) +\n",
    "\\sum_{k = 0}^{C_{\\text{in}} - 1} \\text{weight}(C_{\\text{out}_j}, k) \\star \\text{input}(N_i, k) $$\n",
    "\n",
    "여기서 $\\star$ 는 유효한 2D 교차 상관 연산자 (cross-correlation operator), 𝑁 은 배치 크기, 𝐶 는 채널 수, 𝐻 는 입력 평면의 높이(픽셀), 𝑊 는 폭(픽셀)을 나타냅니다.\n",
    "\n",
    "이 모듈은 TensorFloat32 를 지원합니다.\n",
    "\n",
    "특정 ROCm 장치에서 float16 입력을 사용할 때, 이 모듈은 역방향에 대해 다른 정밀도를 사용합니다.\n",
    "\n",
    "- `stride` 는 교차 상관관계의 보폭, 단일 숫자 또는 튜플을 제어합니다.\n",
    "- `padding` 은 입력에 적용되는 패딩의 양을 제어합니다. 문자열 {'valid', 'same'} 이거나 양쪽에 적용되는 암시적 패딩의 양을 나타내는 정수/정수 튜플일 수 있습니다.\n",
    "- `dilation` 은 커널 포인트 사이의 간격을 제어하며, a` trous (아트르) 알고리즘이라고도 합니다. 설명하기는 어렵지만 이 링크에 확장 기능을 시각화한 멋진 그림이 있습니다.\n",
    "  - <img width=\"100\" src=\"https://github.com/vdumoulin/conv_arithmetic/raw/master/gif/dilation.gif\">\n",
    "- `groups` 는 입력과 출력 간의 연결을 제어합니다. `in_channels`와 `out_channels`는 모두 그룹으로 나눌 수 있어야 합니다. 예를 들어,\n",
    "  - groups=1 에서는 모든 입력이 모든 출력으로 컨볼루션됩니다.\n",
    "  - groups=2 에서 연산은 두 개의 컨볼루션 레이어가 나란히 있고, 각각 절반의 입력 채널을 보고 절반의 출력 채널을 생성하며, 이후 둘 다 연결되는 것과 동일해집니다.\n",
    "  - groups=`in_channels` 에서는 각 입력 채널이 자체 필터 세트(크기가 out_channels/in_channels)로 컨볼루션됩니다.\n",
    "\n",
    "매개변수 `kernel_size`, `stride`, `padding`, `dilation` 은 아래 둘 중 하나가 될 수 있습니다:\n",
    "- 단일 정수 `int` - 이 경우 높이와 너비 차원에 동일한 값이 사용됩니다.\n",
    "- 두 개의 정수로 구성된 `tuple` - 이 경우 첫 번째 정수는 높이 차원에, 두 번째 정수는 너비 차원에 사용됩니다.\n",
    "\n",
    "<br>\n",
    "\n",
    "- 참고\n",
    "  - groups == in_channels 및 out_channels == K * in_channels 에서 K가 양의 정수인 경우, 이 연산을 \"깊이 방향 컨볼루션\" (depthwise convolution) 이라고도 합니다.\n",
    "  - 즉, 크기 (𝑁,𝐶𝑖𝑛,𝐿𝑖𝑛) 입력에서, $(C_\\text{in}=C_\\text{in}, C_\\text{out}=C_\\text{in} \\times \\text{K}, ..., \\text{groups}=C_\\text{in})$ 인수와 함께 깊이 승수 K 를 사용하는 깊이 컨볼루션을 수행할 수 있습니다.\n",
    "- 참고 \n",
    "  - CUDA 장치에 텐서가 주어지고 CuDNN을 사용하는 경우, 이 연산자는 성능을 높이기 위해 비결정론적 알고리즘을 선택할 수 있습니다. 이것이 바람직하지 않은 경우, `torch.backends.cudnn.deterministic = True` 로 설정하여 연산을 결정론적으로 만들 수 있습니다. (잠재적으로 성능 비용이 발생할 수 있음). 자세한 내용은 \"재현성\"을 참조하세요.\n",
    "- 참고\n",
    "  - `padding='valid'` 는 패딩이 없는 것과 동일합니다. `padding='same'` 는 입력을 패딩하여 출력이 입력과 같은 모양을 갖도록 합니다. 그러나 이 모드는 1 이외의 보폭 값은 지원하지 않습니다.\n",
    "- 참고\n",
    "  - 이 모듈은 complex32, complex64, complex128 과 같은 복잡한 데이터 유형을 지원합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0035710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf7371f",
   "metadata": {},
   "source": [
    "### nn.Unfold\n",
    "https://runebook.dev/ko/docs/pytorch/generated/torch.nn.unfold\n",
    "\n",
    "torch.nn.Unfold(kernel_size, dilation=1, padding=0, stride=1)\n",
    "\n",
    "일괄 처리된 입력 텐서에서 슬라이딩 로컬 블록을 추출합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d2cfbf",
   "metadata": {},
   "source": [
    "Consider a batched input tensor of shape (N,C,∗), where N is the batch dimension, C is the channel dimension, and ∗ represent arbitrary spatial dimensions. \n",
    "\n",
    "(N, C,∗) 형태의 배치 입력 텐서를 고려해 보겠습니다. 여기서 N은 배치 차원, C는 채널 차원이며, ∗는 임의의 공간 차원을 나타냅니다.\n",
    "\n",
    "This operation flattens each sliding kernel_size-sized block within the spatial dimensions of input into a column (i.e., last dimension) of a 3-D output tensor of shape (N,C×∏(kernel_size),L), where C×∏(kernel_size) is the total number of values within each block (a block has ∏(kernel_size) spatial locations each containing a C-channeled vector), and L is the total number of such blocks:\n",
    "\n",
    "이 연산은 입력의 공간 차원 내에서 kernel_size 크기의 각 슬라이딩 블록을, (N, C×∏(kernel_size), L) 형태의 3차원 출력 텐서의 열(즉, 마지막 차원)로 평탄화합니다. 여기서 C×∏(kernel_size)는 각 블록 내 값의 총 개수입니다. (블록은 ∏(kernel_size)개의 공간 위치를 가지며, 각 공간 위치는 C채널 벡터를 포함합니다). L은 다음과 같은 블록의 총 개수입니다.\n",
    "\n",
    "$$ L = \\prod_d \\left\\lfloor\\frac{\\text{spatial\\_size}[d] + 2 \\times \\text{padding}[d] %\n",
    "    - \\text{dilation}[d] \\times (\\text{kernel\\_size}[d] - 1) - 1}{\\text{stride}[d]} + 1\\right\\rfloor $$\n",
    "\n",
    "where spatial_size is formed by the spatial dimensions of `input` (∗ above), and d is over all spatial dimensions. <br>\n",
    "여기서 spatial_size는 입력의 공간 차원(위 설명의 ∗)으로 구성되고, d는 모든 공간 차원입니다.\n",
    "\n",
    "Therefore, indexing output at the last dimension (column dimension) gives all values within a certain block. <br>\n",
    "따라서 마지막 차원(열 차원)에서 출력을 인덱싱하면 특정 블록 내의 모든 값이 반환됩니다.\n",
    "\n",
    "The padding, stride and dilation arguments specify how the sliding blocks are retrieved. <br>\n",
    "padding, stride 및 dilation 인수는 슬라이딩 블록을 가져오는 방법을 지정합니다.\n",
    "\n",
    "- stride controls the stride for the sliding blocks.\n",
    "- padding controls the amount of implicit zero-paddings on both sides for padding number of points for each dimension before reshaping.\n",
    "- dilation controls the spacing between the kernel points; also known as the à trous algorithm. It is harder to describe, but this link has a nice visualization of what dilation does.\n",
    "- \n",
    "- stride는 슬라이딩 블록의 stride를 제어합니다.\n",
    "- padding은 각 차원의 점 개수를 패딩하기 위해 양쪽에 암묵적인 0 패딩을 적용하는 양을 제어합니다.\n",
    "- dilation은 커널 점 사이의 간격을 제어합니다. à trous 알고리즘이라고도 합니다. 설명하기는 어렵지만, 이 링크에서 dilation의 기능을 시각적으로 잘 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d05a7a",
   "metadata": {},
   "source": [
    "\n",
    "## Pooling layers\n",
    "\n",
    "Padding Layers\n",
    "\n",
    "Non-linear Activations (weighted sum, nonlinearity)\n",
    "\n",
    "Non-linear Activations (other)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e27dc6",
   "metadata": {},
   "source": [
    "\n",
    "## Normalization Layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1fe99a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### nn.BatchNorm1d\n",
    "\n",
    "Applies Batch Normalization over a 2D or 3D input.\n",
    "\n",
    "### nn.BatchNorm2d\n",
    "\n",
    "Applies Batch Normalization over a 4D input.\n",
    "\n",
    "### nn.BatchNorm3d\n",
    "\n",
    "Applies Batch Normalization over a 5D input.\n",
    "\n",
    "### nn.LazyBatchNorm1d\n",
    "\n",
    "A torch.nn.BatchNorm1d module with lazy initialization.\n",
    "\n",
    "### nn.LazyBatchNorm2d\n",
    "\n",
    "A torch.nn.BatchNorm2d module with lazy initialization.\n",
    "\n",
    "### nn.LazyBatchNorm3d\n",
    "\n",
    "A torch.nn.BatchNorm3d module with lazy initialization.\n",
    "\n",
    "### nn.GroupNorm\n",
    "\n",
    "Applies Group Normalization over a mini-batch of inputs.\n",
    "\n",
    "### nn.SyncBatchNorm\n",
    "\n",
    "Applies Batch Normalization over a N-Dimensional input.\n",
    "\n",
    "### nn.InstanceNorm1d\n",
    "\n",
    "Applies Instance Normalization.\n",
    "\n",
    "### nn.InstanceNorm2d\n",
    "\n",
    "Applies Instance Normalization.\n",
    "\n",
    "### nn.InstanceNorm3d\n",
    "\n",
    "Applies Instance Normalization.\n",
    "\n",
    "### nn.LazyInstanceNorm1d\n",
    "\n",
    "A torch.nn.InstanceNorm1d module with lazy initialization of the num_features argument.\n",
    "\n",
    "### nn.LazyInstanceNorm2d\n",
    "\n",
    "A torch.nn.InstanceNorm2d module with lazy initialization of the num_features argument.\n",
    "\n",
    "### nn.LazyInstanceNorm3d\n",
    "\n",
    "A torch.nn.InstanceNorm3d module with lazy initialization of the num_features argument.\n",
    "\n",
    "### nn.LayerNorm\n",
    "- 미니 배치 입력에 레이어 정규화(Layer Normalization)를 적용.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### nn.LocalResponseNorm\n",
    "\n",
    "Applies local response normalization over an input signal.\n",
    "\n",
    "### nn.RMSNorm\n",
    "\n",
    "Applies Root Mean Square Layer Normalization over a mini-batch of inputs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c640217",
   "metadata": {},
   "source": [
    "\n",
    "Recurrent Layers\n",
    "\n",
    "Transformer Layers\n",
    "\n",
    "Linear Layers\n",
    "\n",
    "Dropout Layers\n",
    "\n",
    "Sparse Layers\n",
    "\n",
    "Distance Functions\n",
    "\n",
    "Loss Functions\n",
    "\n",
    "Vision Layers\n",
    "\n",
    "Shuffle Layers\n",
    "\n",
    "DataParallel Layers (multi-GPU, distributed)\n",
    "\n",
    "Utilities\n",
    "\n",
    "Quantized Functions\n",
    "\n",
    "Lazy Modules Initialization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
